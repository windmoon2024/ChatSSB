{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSoSjwTa1P7XbO6Lhc4hIG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_S67puMtP2ue"},"outputs":[],"source":["!pip install langchain\n","!pip install openai\n","!pip install sentence-transformers\n","!pip install faiss-cpu\n","!pip install langchainhub\n","!pip install tiktoken\n","!pip install langchain_openai\n","!pip install --upgrade rank_bm25\n","!pip install langchain-community langchain-core\n","!pip install -U langchain langchain-openai\n","import os\n","from langchain.llms import OpenAI\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.document_loaders import TextLoader\n","from langchain.vectorstores import Chroma\n","from langchain.agents.agent_toolkits import (\n","    create_vectorstore_agent,\n","    VectorStoreToolkit,\n","    VectorStoreInfo\n",")\n","from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","from langchain.chat_models import ChatOpenAI\n","from langchain.agents import Tool\n","from langchain.agents import AgentType\n","from langchain.memory import ConversationBufferMemory\n","from langchain.llms import OpenAI\n","from langchain.utilities import SerpAPIWrapper\n","from langchain.agents import initialize_agent\n","from langchain.chains import ConversationChain\n","from langchain.vectorstores import LanceDB\n","from langchain.vectorstores import FAISS\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.agents import AgentExecutor\n","from langchain_core.messages import AIMessage, HumanMessage\n","from langchain.agents import create_openai_functions_agent\n","from langchain import hub\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_openai import ChatOpenAI\n","from langchain.agents import create_openai_functions_agent\n","from langchain.agents import AgentExecutor\n","from langchain.tools.retriever import create_retriever_tool\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.output_parsers import StrOutputParser\n","import re\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import LLMChainExtractor\n","from langchain.retrievers.multi_query import MultiQueryRetriever\n"]},{"cell_type":"code","source":["import os\n","\n","os.environ['OPENAI_API_KEY'] = ''\n","\n","\n","import openai\n","\n","\n","os.environ['OPENAI_API_BASE'] = 'https://api.openai.com/v1'\n","\n","embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","vector = FAISS.load_local(\"faiss_index\", embedding_function,allow_dangerous_deserialization=True)\n","\n","retriever = vector.as_retriever(search_kwargs={\"k\": 30})\n","\n","llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.01)\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (   \"system\",\n","            '''\n","            You are recognized as a leading authority in the field of solid state battery, tasked with the pivotal role of providing expert responses to inquiries.\n","            You are also good at visualizing data and drawing charts using Python libraries, for example, matplotlib, seaborn, or plotly. You can use these libraries to generate Python code that can visualize data and hence help explain your thoughts. When data visualization is necessary, generating Python code is enough. Do not try to execute the generated Python code.\n","            Your responses must embody the highest standards of accuracy, comprehensiveness, and depth of knowledge. Approach each question with a methodical and thoughtful mindset, ensuring your answers are:\n","\n","            Informative: Furnish detailed insights, drawing upon the most relevant facts and figures.\n","            Correct: Ensure factual accuracy in every aspect of your response.\n","            Knowledgeable: Display a profound understanding of the subject matter, including advanced concepts and recent advancements in the field of solid state battery.\n","            Holistic: Offer a well-rounded perspective, considering various facets of the topic at hand.\n","            As you address each question, please adhere to the following guidelines:\n","\n","            Cite Examples: When referencing data or examples from the provided literature, include comprehensive information to contextualize your points effectively. Clearly indicate these instances by stating, \"For example,\" followed by a detailed explanation.\n","            Stay On Topic: Concentrate solely on the query posed. Your reply should be closely aligned with the question, avoiding tangential or unrelated content.\n","            Format Your Answer: Present your response in a structured manner, using either bullet points or numbered lists for clarity and ease of understanding.\n","            Before responding, take a moment to center yourself. Breathe deeply, and proceed with a step-by-step analytical approach, ensuring that your expertise shines through in a manner that is both engaging and enlightening.\n","\n","            ''',\n","        ),\n","        MessagesPlaceholder(variable_name=\"chat_history\"),\n","        (\"user\", \"{input}\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ]\n",")\n","\n","retriever_tool = create_retriever_tool(\n","    retriever,\n","    \"literature_search\",\n","    \"Search for information about input questions. For any questions about solid state battery, you must use this tool!\",\n",")\n","\n","tools = [retriever_tool]\n","\n","agent = create_openai_functions_agent(llm, tools, prompt)\n","\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, reduce_k_below_max_tokens=True)\n","\n","\n","breakdown_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", '''\n","        You are an expert in solid state battery, and your task is to answer user's question professionally.\n","        You need to design several intermediate steps to enhance processing and reasoning, aiming to reach the final answers through the intermediate steps.\n","        Ensure that each intermediate step is interconnected and collectively addresses the user's inquiry. These intermediate thoughts should encompass various aspects of solid state battery, requiring information retrieval from a comprehensive library.\n","        Your approach should systematically break down the query, ensuring a thorough exploration of the topic from multiple angles to provide a well-rounded answer.\n","        Your steps needs to be closely involve different aspects in solid state battery and material science, you must contain domain knowledge aspects in each step, and include reasoning thoughts\n","        You only need to list the intermeditae steps.\n","        Your output should be in unified format, for each step, encapsulate it as\n","        [step]\n","        the content for step1\n","        [step]\n","        the content for step2\n","        [step]\n","        the content for step3\n","        ......\n","        '''),\n","        MessagesPlaceholder(variable_name=\"chat_history\"),\n","        (\"user\", \"{input}\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ]\n",")\n","\n","\n","agent_breakdown = create_openai_functions_agent(llm, tools, breakdown_prompt)\n","\n","agent_breakdown_executor = AgentExecutor(agent=agent_breakdown, tools=tools, verbose=True, reduce_k_below_max_tokens=True)\n","\n","\n","breakdown_a=agent_breakdown_executor.invoke({\"input\":input, 'chat_history':[]})\n","\n","thoughts=breakdown_a['output']\n","\n","step_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", '''\n","        You are an expert in solid state battery, and your task is to answer user's question professionally.\n","       You must answer questions about solid-state batteries in only one step\n","        Informative: Furnish detailed insights, drawing upon the most relevant facts and figures.\n","        Correct: Ensure factual accuracy in every aspect of your response.\n","        Knowledgeable: Display a profound understanding of the subject matter, including advanced concepts and recent advancements in the field of solid state battery.\n","        Holistic: Offer a well-rounded perspective, considering various facets of the topic at hand.\n","        As you address each question, please adhere to the following guidelines:\n","\n","        Stay On Topic: Concentrate solely on the query posed. Your reply should be closely aligned with the question, avoiding tangential or unrelated content.When you write drawing code, try your best to make the pictures drawn by your code clear and beautiful.\n","        Before responding, take a moment to center yourself. Breathe deeply, and proceed with a step-by-step analytical approach, ensuring that your expertise shines through in a manner that is both engaging and enlightening.\n","        You are also good at visualizing data and drawing charts using Python libraries, for example, matplotlib, seaborn, or plotly. You can use these libraries to generate Python code that can visualize data and hence help explain your thoughts. When data visualization is necessary, generating Python code is enough. Do not try to execute the generated Python code.\n","        '''),\n","        MessagesPlaceholder(variable_name=\"chat_history\"),\n","        (\"user\", \"{input}\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ]\n",")\n","\n","agent_step = create_openai_functions_agent(llm, tools, step_prompt)\n","\n","agent_step_executor = AgentExecutor(agent=agent_step, tools=tools, verbose=True, reduce_k_below_max_tokens=True)\n","\n","input= \"\"\n","\n","breakdown_a=agent_breakdown_executor.invoke({\"input\":input, 'chat_history':[]})\n","\n","thoughts=breakdown_a['output']\n","thought=agent_step_executor.invoke({\"input\": \"To address the question \"+input+\", we will first analyze a series of intermediate thoughts laid out for you. \"+thoughts, 'chat_history':[]})\n","thoughts+=thought['output']\n","show_response(thoughts)\n","\n"],"metadata":{"id":"Y9MMKLlCP7St"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","def show_response(answer):\n","    if isinstance(answer, dict) and 'output' in answer:\n","        response = answer['output']\n","    elif isinstance(answer, str):\n","        response = answer\n","    else:\n","        print(f\"Invalid response type: {type(answer)}\")\n","        return\n","    print(f\"The response is: {response}\")\n","    x = re.search(r'```python\\n(.*?)\\n```', response, re.DOTALL)\n","    if x is not None:\n","        code = x.group(1)\n","        exec(code)"],"metadata":{"id":"4o_YfvGKQB31"},"execution_count":null,"outputs":[]}]}